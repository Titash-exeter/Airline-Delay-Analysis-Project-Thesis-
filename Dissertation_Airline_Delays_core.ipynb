{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c5a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dataset Saved: Data_clean\\flights_2015_ATL-LAX_JFK-ORD.csv\n",
      "On-time confidence intervals saved: Outputs\\otp_confidence_intervals.csv\n",
      "KPI table saved: Outputs\\kpi_by_routepair.csv\n",
      "KPI by direction table saved: Outputs\\kpi_by_direction.csv\n",
      "KPI for stable months table saved: Outputs\\kpi_by_routepair_stable_months.csv\n",
      " Cleaned file: Data_clean\\flights_2015_ATL-LAX_JFK-ORD.csv\n",
      " Tables:      ./Outputs/*.csv\n",
      " Figures:     ./Outputs/*.png\n"
     ]
    }
   ],
   "source": [
    "# filename: Dissertation_Airline_Delays_core.py\n",
    "# Inputs: flights.csv, airlines.csv, airports.csv\n",
    "# Outputs:\n",
    "# Data_clean -> flights_2015_ATL-LAX_JFK-ORD.csv\n",
    "# Outputs -> KPIs, cause mix, schedule padding, time series, Figures used in the Dissertation\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# ---------------------------\n",
    "# 0) Paths & setup\n",
    "# ---------------------------\n",
    "# Define input file paths (BTS/Kaggle datasets) and output folders\n",
    "\n",
    "FLIGHTS_PATH  = \"flights.csv\"\n",
    "AIRLINES_PATH = \"airlines.csv\"\n",
    "AIRPORTS_PATH = \"airports.csv\"\n",
    "\n",
    "OUT_DATA_DIR = \"Data_clean\"\n",
    "OUT_DIR      = \"Outputs\"\n",
    "os.makedirs(OUT_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Reading and filtering of data \n",
    "# ---------------------------\n",
    "# I only read the columns needed, and streamed the big file in chunks.\n",
    "# Then I kept only flights between ATL–LAX and JFK–ORD (both directions).\n",
    "\n",
    "COLUMNS = [\"YEAR\",\"MONTH\",\"DAY\",\"AIRLINE\",\"FLIGHT_NUMBER\",\n",
    "           \"ORIGIN_AIRPORT\",\"DESTINATION_AIRPORT\",\n",
    "           \"SCHEDULED_DEPARTURE\",\"DEPARTURE_TIME\",\"DEPARTURE_DELAY\",\n",
    "           \"SCHEDULED_ARRIVAL\",\"ARRIVAL_TIME\",\"ARRIVAL_DELAY\",\n",
    "           \"SCHEDULED_TIME\",\"ELAPSED_TIME\",\"DISTANCE\",\n",
    "           \"DIVERTED\",\"CANCELLED\",\n",
    "           \"AIR_SYSTEM_DELAY\",\"SECURITY_DELAY\",\"AIRLINE_DELAY\",\"LATE_AIRCRAFT_DELAY\",\"WEATHER_DELAY\"]\n",
    "\n",
    "routes = {\"ATL\", \"LAX\", \"JFK\", \"ORD\"}\n",
    "pairs = {(\"ATL\", \"LAX\"), (\"LAX\", \"ATL\"), (\"JFK\", \"ORD\"), (\"ORD\", \"JFK\")}\n",
    "\n",
    "filtered_part = []\n",
    "for chunk in pd.read_csv(FLIGHTS_PATH, usecols=COLUMNS, chunksize=1_000_000, low_memory=False):\n",
    "    # only rows where both origin and destination are one of the 4 airports\n",
    "    a = chunk[\"ORIGIN_AIRPORT\"].isin(routes) & chunk[\"DESTINATION_AIRPORT\"].isin(routes)\n",
    "    if not a.any(): \n",
    "        continue\n",
    "    \n",
    "    c = chunk[a]\n",
    "    # built (origin, dest) pairs and kept only ATL–LAX / JFK–ORD in both directions\n",
    "    b = list(zip(c[\"ORIGIN_AIRPORT\"], c[\"DESTINATION_AIRPORT\"]))\n",
    "    c = c[[t in pairs for t in b]]\n",
    "    # restrict to year 2015\n",
    "    c = c[c[\"YEAR\"] == 2015]\n",
    "    \n",
    "    if len(c):\n",
    "        filtered_part.append(c)\n",
    "\n",
    "# concatenated all matching chunks into one DataFrame\n",
    "p = pd.concat(filtered_part, ignore_index=True)\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Feature Engineering\n",
    "# ---------------------------\n",
    "# Created route-level variables, flags, and derived time fields.\n",
    "\n",
    "p[\"FlightDate\"] = pd.to_datetime(p[[\"YEAR\", \"MONTH\", \"DAY\"]])\n",
    "p[\"Month\"] = p[\"FlightDate\"].dt.month\n",
    "\n",
    "# Collapsed directions into a bi-directional RoutePair (ATL-LAX vs JFK-ORD)\n",
    "p[\"RoutePair\"] = np.where(p[\"ORIGIN_AIRPORT\"].isin([\"ATL\", \"LAX\"]), \"ATL-LAX\", \"JFK-ORD\")\n",
    "\n",
    "# Kept true direction separately, e.g. \"ATL→LAX\"\n",
    "p[\"Direction\"] = p[\"ORIGIN_AIRPORT\"] + \"→\" + p[\"DESTINATION_AIRPORT\"]\n",
    "\n",
    "# Cleaned cancelled and diverted flights\n",
    "p[\"Cancelled\"] = p[\"CANCELLED\"].fillna(0).astype(int)\n",
    "p[\"Diverted\"]  = p[\"DIVERTED\"].fillna(0).astype(int)\n",
    "\n",
    "# Vectorized hour from HHMM scheduled departure (local origin time)\n",
    "dep_num = pd.to_numeric(p[\"SCHEDULED_DEPARTURE\"], errors=\"coerce\")\n",
    "p[\"DepHourLocal\"] = (dep_num // 100).astype(\"Int16\")\n",
    "\n",
    "# Create Delayed15 flag (only for operated flights, NaN otherwise)\n",
    "mask_op = (p[\"Cancelled\"] == 0) & (p[\"Diverted\"] == 0)\n",
    "p.loc[mask_op, \"Delayed_by_15 min\"] = (p.loc[mask_op, \"ARRIVAL_DELAY\"] >= 15).astype(int)\n",
    "\n",
    "# Subset of operated flights used in most KPIs\n",
    "operated = p[mask_op].copy()\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Saved the cleaned subset used in the report\n",
    "# ---------------------------\n",
    "# This is the dataset used for analysis.\n",
    "\n",
    "filtered_cols = [\n",
    "    \"FlightDate\",\"AIRLINE\",\"FLIGHT_NUMBER\",\"ORIGIN_AIRPORT\",\"DESTINATION_AIRPORT\",\n",
    "    \"SCHEDULED_DEPARTURE\",\"DEPARTURE_TIME\",\"DEPARTURE_DELAY\",\n",
    "    \"SCHEDULED_ARRIVAL\",\"ARRIVAL_TIME\",\"ARRIVAL_DELAY\",\n",
    "    \"SCHEDULED_TIME\",\"ELAPSED_TIME\",\"DISTANCE\",\n",
    "    \"Cancelled\",\"Diverted\",\"RoutePair\",\"Direction\",\"Month\",\"DepHourLocal\",\"Delayed_by_15 min\",\n",
    "    \"AIR_SYSTEM_DELAY\",\"SECURITY_DELAY\",\"AIRLINE_DELAY\",\"LATE_AIRCRAFT_DELAY\",\"WEATHER_DELAY\"\n",
    "]\n",
    "filtered = p[filtered_cols].copy()\n",
    "filtered_path = os.path.join(OUT_DATA_DIR, \"flights_2015_ATL-LAX_JFK-ORD.csv\")\n",
    "filtered.to_csv(filtered_path, index=False)\n",
    "print(f\"Filtered Dataset Saved: {filtered_path}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4) KPIs (per route pair)\n",
    "# ---------------------------\n",
    "# First: main KPIs at RoutePair level (ATL-LAX vs JFK-ORD).\n",
    "\n",
    "def kpis_by_routepair(all, op):\n",
    "    rows = []\n",
    "    for rp, g_sched in all.groupby(\"RoutePair\"):\n",
    "        scheduled = len(g_sched)\n",
    "        canc = int(g_sched[\"Cancelled\"].sum())\n",
    "        div  = int(g_sched[\"Diverted\"].sum())\n",
    "\n",
    "        g = op[op[\"RoutePair\"] == rp]\n",
    "        operated_n = len(g)\n",
    "\n",
    "        if operated_n:\n",
    "            pct_ge15  = 100.0 * g[\"ARRIVAL_DELAY\"].ge(15).mean()   # % flights >=15 min late\n",
    "            pct_ge60  = 100.0 * g[\"ARRIVAL_DELAY\"].ge(60).mean()   # % flights >=60 min late\n",
    "            ontime_pct = 100.0 - pct_ge15\n",
    "            avg_delay  = g[\"ARRIVAL_DELAY\"].mean()\n",
    "        else:\n",
    "            pct_ge15 = pct_ge60 = ontime_pct = avg_delay = np.nan\n",
    "\n",
    "        rows.append(dict(\n",
    "            RoutePair=rp,\n",
    "            flights_scheduled=scheduled,\n",
    "            flights_operated=operated_n,\n",
    "            cancellations=canc,\n",
    "            cancellation_rate=100.0 * canc / scheduled if scheduled else np.nan,\n",
    "            pct_delay_ge15=pct_ge15,              \n",
    "            pct_delay_ge60=pct_ge60,              \n",
    "            ontime_pct=ontime_pct,\n",
    "            avg_arrival_delay_min=avg_delay\n",
    "        ))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Second: KPIs by Direction (ATL→LAX, LAX→ATL, JFK→ORD, ORD→JFK)\n",
    "def kpis_by_direction(all, op):\n",
    "    rows = []\n",
    "    for d, g_sched in all.groupby(\"Direction\"):\n",
    "        scheduled = len(g_sched)\n",
    "        canc = int(g_sched[\"Cancelled\"].sum())\n",
    "        div  = int(g_sched[\"Diverted\"].sum())\n",
    "\n",
    "        g = op[op[\"Direction\"] == d]\n",
    "        operated_n = len(g)\n",
    "\n",
    "        if operated_n:\n",
    "            pct_ge15  = 100.0 * g[\"ARRIVAL_DELAY\"].ge(15).mean()\n",
    "            pct_ge60  = 100.0 * g[\"ARRIVAL_DELAY\"].ge(60).mean()\n",
    "            ontime_pct = 100.0 - pct_ge15\n",
    "            avg_delay  = g[\"ARRIVAL_DELAY\"].mean()\n",
    "        else:\n",
    "            pct_ge15 = pct_ge60 = ontime_pct = avg_delay = np.nan\n",
    "\n",
    "        rows.append(dict(\n",
    "            Direction=d,\n",
    "            flights_scheduled=scheduled,\n",
    "            flights_operated=operated_n,\n",
    "            cancellations=canc,\n",
    "            cancellation_rate=100.0 * canc / scheduled if scheduled else np.nan,\n",
    "            pct_delay_ge15=pct_ge15,\n",
    "            pct_delay_ge60=pct_ge60,\n",
    "            ontime_pct=ontime_pct,\n",
    "            avg_arrival_delay_min=avg_delay\n",
    "        ))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Main route-pair KPI table\n",
    "kpi = kpis_by_routepair(p, operated)\n",
    "\n",
    "def add_otp_confidenceinterval(df, operated_df):\n",
    "    # Approximate 95% confidence intervals for on-time percentage per RoutePair\n",
    "    rows = []\n",
    "    for rp, g in operated_df.groupby(\"RoutePair\"):\n",
    "        n = len(g)\n",
    "        if n == 0:\n",
    "            continue\n",
    "        p_hat = (g[\"ARRIVAL_DELAY\"] < 15).mean()\n",
    "        # Normal approx 95% CI\n",
    "        z = 1.96\n",
    "        se = sqrt(p_hat * (1 - p_hat) / n)\n",
    "        lower = max(0, p_hat - z * se)\n",
    "        upper = min(1, p_hat + z * se)\n",
    "        rows.append({\"RoutePair\": rp,\n",
    "                     \"n_operated\": n,\n",
    "                     \"otp_prop\": p_hat,\n",
    "                     \"otp_ci_lower\": lower,\n",
    "                     \"otp_ci_upper\": upper})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Confidence interval table for OTP\n",
    "otp_CI = add_otp_confidenceinterval(kpi, operated)\n",
    "otp_CI_path = os.path.join(OUT_DIR, \"otp_confidence_intervals.csv\")\n",
    "otp_CI.to_csv(otp_CI_path, index=False)\n",
    "print(f\"On-time confidence intervals saved: {otp_CI_path}\")\n",
    "\n",
    "# Saved KPI by route pair\n",
    "kpi_path = os.path.join(OUT_DIR, \"kpi_by_routepair.csv\")\n",
    "kpi.to_csv(kpi_path, index=False)\n",
    "print(f\"KPI table saved: {kpi_path}\")\n",
    "\n",
    "# KPI by direction (for ATL→LAX vs LAX→ATL, JFK→ORD vs ORD→JFK)\n",
    "kpi_dir = kpis_by_direction(p, operated)\n",
    "kpi_dir_path = os.path.join(OUT_DIR, \"kpi_by_direction.csv\")\n",
    "kpi_dir.to_csv(kpi_dir_path, index=False)\n",
    "print(f\"KPI by direction table saved: {kpi_dir_path}\")\n",
    "\n",
    "# Defined “stable” months for robustness (excluded Jan, Feb, Jun, Jul)\n",
    "stable_months = [3, 4, 5, 8, 9, 10, 11, 12]\n",
    "\n",
    "p_stable = p[p[\"Month\"].isin(stable_months)].copy()\n",
    "operated_stable = operated[operated[\"Month\"].isin(stable_months)].copy()\n",
    "\n",
    "kpi_stable = kpis_by_routepair(p_stable, operated_stable)\n",
    "kpi_stable_path = os.path.join(OUT_DIR, \"kpi_by_routepair_stable_months.csv\")\n",
    "kpi_stable.to_csv(kpi_stable_path, index=False)\n",
    "print(f\"KPI for stable months table saved: {kpi_stable_path}\")\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Monthly on-time % (per route pair)\n",
    "# ---------------------------\n",
    "# Computed and exported monthly on-time percentage per RoutePair, plus a line chart.\n",
    "\n",
    "monthly = (operated.groupby([\"RoutePair\",\"Month\"])[\"Delayed_by_15 min\"].apply(lambda s: 100*(1 - s.mean())).reset_index(name=\"OnTimePct\"))\n",
    "monthly_path = os.path.join(OUT_DIR, \"monthly_otp_by_routepair.csv\")\n",
    "monthly.to_csv(monthly_path, index=False)\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "for rp, g in monthly.groupby(\"RoutePair\"):\n",
    "    k = g.sort_values(\"Month\")\n",
    "    plt.plot(k[\"Month\"], k[\"OnTimePct\"], marker=\"o\", label=rp)\n",
    "plt.title(\"Monthly On-Time % (Arrival < 15 min late) 2015\")\n",
    "plt.xlabel(\"Month\"); plt.ylabel(\"On-Time Percentage\"); plt.ylim(0,100); plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(1,13)); plt.legend()\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR, \"Monthly_On-time_Performance.png\"), dpi=200); plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Hour-of-day on-time % (per route pair)\n",
    "# ---------------------------\n",
    "# Computed and exported OTP by scheduled departure hour (DepHourLocal) and RoutePair.\n",
    "\n",
    "hod = (operated[operated[\"DepHourLocal\"].notna()].groupby([\"RoutePair\",\"DepHourLocal\"])[\"Delayed_by_15 min\"].apply(lambda s: 100*(1 - s.mean())).reset_index(name=\"OnTimePct\"))\n",
    "hod_path = os.path.join(OUT_DIR, \"Hour_of_Day_OTP_by_routepair.csv\")\n",
    "hod.to_csv(hod_path, index=False)\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "for rp, g in hod.groupby(\"RoutePair\"):\n",
    "    k = g.sort_values(\"DepHourLocal\")\n",
    "    plt.plot(k[\"DepHourLocal\"], k[\"OnTimePct\"], marker=\"o\", label=rp)\n",
    "plt.title(\"On-Time % by Scheduled Departure Hour 2015\")\n",
    "plt.xlabel(\"Scheduled Departure Hour (local)\"); plt.ylabel(\"On-Time Percentage\"); plt.ylim(0,100)\n",
    "plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, \"Hour_of_Day_On-time_Performance.png\"), dpi=200); plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Delay distribution (histograms) per route pair\n",
    "# ---------------------------\n",
    "# Histograms of arrival delays, clipped to [-30, 180] minutes for readability.\n",
    "\n",
    "for rp in operated[\"RoutePair\"].unique():\n",
    "    x = operated.loc[operated[\"RoutePair\"]==rp, \"ARRIVAL_DELAY\"].clip(lower=-30, upper=180)\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    plt.hist(x.dropna(), bins=40)\n",
    "    plt.title(f\"Arrival Delay Distribution — {rp} (2015)\")\n",
    "    plt.xlabel(\"Arrival Delay (minutes)\"); plt.ylabel(\"Flights\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, f\"delay_hist_{rp.replace('-','_')}.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Delay cause mix (minutes) per route pair\n",
    "#    (AIRLINE_DELAY = carrier; WEATHER_DELAY = weather; AIR_SYSTEM_DELAY = NAS; SECURITY_DELAY; LATE_AIRCRAFT_DELAY)\n",
    "# ---------------------------\n",
    "# Aggregated delay minutes by cause to build the cause mix tables and chart.\n",
    "\n",
    "cause_cols = [\"AIRLINE_DELAY\",\"WEATHER_DELAY\",\"AIR_SYSTEM_DELAY\",\"SECURITY_DELAY\",\"LATE_AIRCRAFT_DELAY\"]\n",
    "cause = (operated.groupby(\"RoutePair\")[cause_cols].sum(min_count=1).reset_index())\n",
    "cause.to_csv(os.path.join(OUT_DIR, \"delay_cause_minutes_by_routepair.csv\"), index=False)\n",
    "\n",
    "# Shares (Percentage of total delay minutes reported)\n",
    "Shares = cause.copy()\n",
    "Total = Shares[cause_cols].sum(axis=1)\n",
    "for w in cause_cols:\n",
    "    Shares[w + \"_SHARE\"] = (Shares[w] / Total) * 100\n",
    "share_cols = [\"RoutePair\"] + [w + \"_SHARE\" for w in cause_cols]\n",
    "Shares[share_cols].to_csv(os.path.join(OUT_DIR, \"delay_cause_shares_by_routepair.csv\"), index=False)\n",
    "\n",
    "# stacked bar\n",
    "plot = cause.set_index(\"RoutePair\")[cause_cols].fillna(0)\n",
    "if plot.to_numpy().sum() > 0:\n",
    "    plot.plot(kind=\"bar\", stacked=True, figsize=(7,4.5))\n",
    "    plt.ylabel(\"Delay Minutes (sum)\"); plt.title(\"Delay Cause Minutes 2015\")\n",
    "    plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR, \"Delay_Cause_Stacked.png\"), dpi=200); plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# 9) Schedule padding (block-time slack)\n",
    "#    padding = median(SCHEDULED_TIME) − median(ELAPSED_TIME among on-time flights)\n",
    "#    computed by Direction (ATL→LAX, LAX→ATL, JFK→ORD, ORD→JFK) and by Month\n",
    "# ---------------------------\n",
    "# Estimated how much schedule padding exists by direction, using only on-time flights for the unimpeded actual time.\n",
    "# Unimpeded actual = median ELAPSED_TIME among on-time flights (ARRIVAL_DELAY < 15)\n",
    "\n",
    "unimpeded = (operated[operated[\"Delayed_by_15 min\"]==0].groupby(\"Direction\")[\"ELAPSED_TIME\"].median().rename(\"UnimpededMedian_ACT_minutes\").reset_index())\n",
    "\n",
    "scheduled = (operated.groupby(\"Direction\")[\"SCHEDULED_TIME\"].median().rename(\"Median_Scheduled_minutes\").reset_index())\n",
    "\n",
    "padding = pd.merge(scheduled, unimpeded, on=\"Direction\", how=\"left\")\n",
    "padding[\"Padding_minutes\"] = padding[\"Median_Scheduled_minutes\"] - padding[\"UnimpededMedian_ACT_minutes\"]\n",
    "padding_direction = padding.sort_values(\"Direction\")\n",
    "padding_path = os.path.join(OUT_DIR, \"schedule_padding_by_direction.csv\")\n",
    "padding_direction.to_csv(padding_path, index=False)\n",
    "\n",
    "plt.figure(figsize=(8,4.8))\n",
    "x = np.arange(len(padding_direction))\n",
    "plt.bar(x, padding_direction[\"Padding_minutes\"])\n",
    "plt.xticks(x, padding_direction[\"Direction\"], rotation=20)\n",
    "plt.ylabel(\"Padding (minutes)\")\n",
    "plt.title(\"Schedule Padding by Direction (Median Scheduled - Median Unimpeded Actual)\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT_DIR, \"Padding_by_Direction.png\"), dpi=200); plt.close()\n",
    "\n",
    "# Monthly padding by direction (for self use)\n",
    "unimpeded_monthly = (operated[operated[\"Delayed_by_15 min\"]==0].groupby([\"Direction\",\"Month\"])[\"ELAPSED_TIME\"].median().rename(\"Unimpeded_median\").reset_index())\n",
    "scheduled_monthly = (operated.groupby([\"Direction\",\"Month\"])[\"SCHEDULED_TIME\"].median().rename(\"Scheduled_median\").reset_index())\n",
    "pm = pd.merge(scheduled_monthly, unimpeded_monthly, on=[\"Direction\",\"Month\"], how=\"left\")\n",
    "pm[\"Padding_minutes\"] = pm[\"Scheduled_median\"] - pm[\"Unimpeded_median\"]\n",
    "pm.to_csv(os.path.join(OUT_DIR, \"Schedule_Padding_Monthly_by_Direction.csv\"), index=False)\n",
    "\n",
    "for d in sorted(pm[\"Direction\"].unique()):\n",
    "    a = pm[pm[\"Direction\"]==d].sort_values(\"Month\")\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    plt.plot(a[\"Month\"], a[\"Padding_minutes\"], marker=\"o\")\n",
    "    plt.title(f\"Monthly Schedule Padding — {d} (2015)\")\n",
    "    plt.xlabel(\"Month\"); plt.ylabel(\"Padding (minutes)\"); plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(range(1,13)); plt.tight_layout()\n",
    "    fn = f\"padding_monthly_{d.replace('→','to')}.png\"\n",
    "    plt.savefig(os.path.join(OUT_DIR, fn), dpi=200); plt.close()\n",
    "\n",
    "print(\" Cleaned file:\", filtered_path)\n",
    "print(\" Tables:      ./Outputs/*.csv\")\n",
    "print(\" Figures:     ./Outputs/*.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
